1. Считайте файл 3.csv и создайте Spark DataFrame.
2. Подсчитайте количество пропусков
3. Обработайте пропуски: заполните средним по колонке
4. Произведите фильтрацию данных: оставьте строки, сумма которых < 0
5. Подсчитайте статистику по каждой колонке и сохранить в отдельный df.
6. Запишите полученный df со статистикой: r_3.csv